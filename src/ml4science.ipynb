{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsOvkQ_CmG6z"
   },
   "source": [
    "# Packed Ensemble Application to the AirfRANS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `colab` to `True` if you wish to use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2228,
     "status": "ok",
     "timestamp": 1701505614095,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "0rUcVZoTmI7A",
    "outputId": "25da29da-fbb4-40e5-b2a7-1e0c04edd420",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:47.717056600Z",
     "start_time": "2024-02-07T11:03:47.673461300Z"
    }
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    !source/content/drive/MyDrive/my_colab_env/bin/activate\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    sys.path.append(\"/content/drive/MyDrive/my_colab_env/lib/python3.10/site-packages\")\n",
    "    os.chdir(\"/content/drive/MyDrive/ml4science/ml4physim_startingkit\")\n",
    "\n",
    "    sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQWKckDomG65"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrkPT3UcmG66"
   },
   "source": [
    "Install the LIPS framework if it is not already done. For more information look at the LIPS framework [Github repository](https://github.com/IRT-SystemX/LIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701505615102,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "g54uEia8mG67",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:47.718057400Z",
     "start_time": "2024-02-07T11:03:47.678051500Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# or\n",
    "# !pip install -U ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD9DFGIamG69"
   },
   "source": [
    "\n",
    "Install the AirfRANS package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1701505621668,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "DUEm2XlhmG69",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:47.739057Z",
     "start_time": "2024-02-07T11:03:47.710057700Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install airfrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:53.007110700Z",
     "start_time": "2024-02-07T11:03:47.726057700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lips import get_root_path\n",
    "from lips.dataset.scaler.standard_scaler import StandardScaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "from lips.dataset.airfransDataSet import download_data\n",
    "\n",
    "from my_packed_ensemble import *\n",
    "from my_packed_cv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDNZhB1tmG6-"
   },
   "source": [
    "## Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701505622617,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "23XBnSjnmG6_",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:53.023131800Z",
     "start_time": "2024-02-07T11:03:53.010085500Z"
    }
   },
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../src/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzJsnBWRmG6_"
   },
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701505623020,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "fZ9nrutLmG7A",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:53.048082200Z",
     "start_time": "2024-02-07T11:03:53.025086700Z"
    }
   },
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"benchmarks\",\n",
    "                                 \"confAirfoil.ini\")  #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"simulators\", \"torch_fc.ini\")  #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qovzIDjOmG7A"
   },
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2186,
     "status": "ok",
     "timestamp": 1701505627135,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "TIo_MeNVmG7B",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:53.064143500Z",
     "start_time": "2024-02-07T11:03:53.040080800Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tWfcbpNmG7B"
   },
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20655,
     "status": "ok",
     "timestamp": 1701505649736,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "cZujz-mpmG7B",
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:59.855628300Z",
     "start_time": "2024-02-07T11:03:53.057126700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets, if it is not pickled, pickle it for future use\n",
    "try:\n",
    "    with open('benchmark.pkl', 'rb') as f:\n",
    "        benchmark = pickle.load(f)\n",
    "except:\n",
    "    benchmark = AirfRANSBenchmark(benchmark_path=DIRECTORY_NAME,\n",
    "                                  config_path=BENCH_CONFIG_PATH,\n",
    "                                  benchmark_name=BENCHMARK_NAME,\n",
    "                                  log_path=LOG_PATH)\n",
    "    benchmark.load(path=DIRECTORY_NAME)\n",
    "    with open('benchmark.pkl', 'wb') as f:\n",
    "        pickle.dump(benchmark, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dict = {\n",
    "    \"evaluateonly\": False,\n",
    "      \"scoringonly\": False,\n",
    "      \"simulator_config\": {\n",
    "        \"simulator_type\": \"custom\",\n",
    "        \"simulator_file\": \"my_packed_ensemble_mk2\",\n",
    "        \"name\": \"MyAugmentedSimulator\",\n",
    "        \"model\": \"AugmentedSimulator\",\n",
    "        \"scaler_type\": \"None\"\n",
    "       },\n",
    "      \"simulator_extra_parameters\": {\n",
    "        \"input_size\": 7,\n",
    "        \"output_size\": 4,\n",
    "        \"hidden_sizes\": [64,64,8,64,64,64,8,64,64],\n",
    "        \"M\": 8,\n",
    "        \"alpha\": 4,\n",
    "        \"gamma\": 1,\n",
    "        \"device\": \"cuda\",\n",
    "    \n",
    "        \"batch_size\": 1,\n",
    "        \"nb_epochs\": 600,\n",
    "        \"lr\": 0.001,\n",
    "        \"subsampling\": 32000\n",
    "      },\n",
    "      \"training_config\": {}\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:03:59.870966900Z",
     "start_time": "2024-02-07T11:03:59.857627400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import new_submission.my_packed_ensemble_mk2 as my_packed_ensemble_mk2\n",
    "\n",
    "simulator = my_packed_ensemble_mk2.AugmentedSimulator(benchmark, **dict[\"simulator_extra_parameters\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:04:01.263331300Z",
     "start_time": "2024-02-07T11:03:59.872967800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize train data\n",
      "Transform done\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/600 [00:09<1:36:06,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/600 [00:18<1:32:45,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/600 [00:27<1:31:45,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/600 [00:36<1:31:15,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/600 [00:46<1:31:07,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/600 [00:55<1:30:59,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/600 [01:04<1:30:28,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 8/600 [01:13<1:30:07,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/600 [01:22<1:29:52,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/600 [01:31<1:29:43,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/600 [01:40<1:29:17,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/600 [01:49<1:29:21,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/600 [01:58<1:28:58,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/600 [02:08<1:28:52,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 15/600 [02:17<1:29:03,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/600 [02:26<1:29:04,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/600 [02:35<1:28:35,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/600 [02:44<1:28:30,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/600 [02:53<1:28:36,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/600 [03:02<1:28:12,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 21/600 [03:12<1:28:11,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 22/600 [03:21<1:28:11,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 23/600 [03:30<1:28:14,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 24/600 [03:39<1:28:09,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 25/600 [03:48<1:27:59,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 26/600 [03:57<1:27:24,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 27/600 [04:06<1:26:48,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 27/600 [04:13<1:29:49,  9.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msimulator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Projects\\EPFL\\ML\\ML-WhAI\\ml-project-2-whai-tmp\\ml4physim_startingkit\\src\\new_submission\\my_packed_ensemble_mk2.py:330\u001B[0m, in \u001B[0;36mAugmentedSimulator.train\u001B[1;34m(self, train_dataset, save_path)\u001B[0m\n\u001B[0;32m    328\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_dataset(dataset\u001B[38;5;241m=\u001B[39mtrain_dataset,training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStart training\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 330\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mglobal_train\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMSE_weighted\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining done\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Projects\\EPFL\\ML\\ML-WhAI\\ml-project-2-whai-tmp\\ml4physim_startingkit\\src\\new_submission\\my_packed_ensemble_mk2.py:426\u001B[0m, in \u001B[0;36mglobal_train\u001B[1;34m(device, train_dataset, network, hparams, criterion, reg)\u001B[0m\n\u001B[0;32m    423\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset_sampled, batch_size \u001B[38;5;241m=\u001B[39m hparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m], shuffle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    424\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m(train_dataset_sampled)\n\u001B[1;32m--> 426\u001B[0m train_loss, _, loss_surf_var, loss_vol_var, loss_surf, loss_vol \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mreg\u001B[49m\u001B[43m)\u001B[49m        \n\u001B[0;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m criterion \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE_weighted\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    428\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m reg\u001B[38;5;241m*\u001B[39mloss_surf \u001B[38;5;241m+\u001B[39m loss_vol\n",
      "File \u001B[1;32mD:\\Projects\\EPFL\\ML\\ML-WhAI\\ml-project-2-whai-tmp\\ml4physim_startingkit\\src\\new_submission\\my_packed_ensemble_mk2.py:453\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(device, model, train_loader, optimizer, scheduler, criterion, reg)\u001B[0m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m    452\u001B[0m     data_clone \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m--> 453\u001B[0m     data_clone \u001B[38;5;241m=\u001B[39m \u001B[43mdata_clone\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m   \n\u001B[0;32m    454\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()  \n\u001B[0;32m    455\u001B[0m     out \u001B[38;5;241m=\u001B[39m model(data_clone)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml4science\\lib\\site-packages\\torch_geometric\\data\\data.py:297\u001B[0m, in \u001B[0;36mBaseData.to\u001B[1;34m(self, device, non_blocking, *args)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto\u001B[39m(\u001B[38;5;28mself\u001B[39m, device: Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m], \u001B[38;5;241m*\u001B[39margs: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m    294\u001B[0m        non_blocking: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    295\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001B[39;00m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    298\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml4science\\lib\\site-packages\\torch_geometric\\data\\data.py:280\u001B[0m, in \u001B[0;36mBaseData.apply\u001B[1;34m(self, func, *args)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001B[39;00m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001B[39;00m\n\u001B[0;32m    279\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m store \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstores:\n\u001B[1;32m--> 280\u001B[0m     \u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml4science\\lib\\site-packages\\torch_geometric\\data\\storage.py:191\u001B[0m, in \u001B[0;36mBaseStorage.apply\u001B[1;34m(self, func, *args)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001B[39;00m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems(\u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m--> 191\u001B[0m     \u001B[38;5;28mself\u001B[39m[key] \u001B[38;5;241m=\u001B[39m \u001B[43mrecursive_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml4science\\lib\\site-packages\\torch_geometric\\data\\storage.py:743\u001B[0m, in \u001B[0;36mrecursive_apply\u001B[1;34m(data, func)\u001B[0m\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrecursive_apply\u001B[39m(data: Any, func: Callable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Tensor):\n\u001B[1;32m--> 743\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mrnn\u001B[38;5;241m.\u001B[39mPackedSequence):\n\u001B[0;32m    745\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(data)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml4science\\lib\\site-packages\\torch_geometric\\data\\data.py:298\u001B[0m, in \u001B[0;36mBaseData.to.<locals>.<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto\u001B[39m(\u001B[38;5;28mself\u001B[39m, device: Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m], \u001B[38;5;241m*\u001B[39margs: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m    294\u001B[0m        non_blocking: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    295\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001B[39;00m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001B[39;00m\n\u001B[0;32m    297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply(\n\u001B[1;32m--> 298\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;241m*\u001B[39margs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "simulator.train(benchmark.train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:14:46.365539400Z",
     "start_time": "2024-02-07T11:10:24.573986900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "0zh_rdsXmG7C"
   },
   "source": [
    "## Model selection (Cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmjFPEN9mG7C"
   },
   "source": [
    "Importing the necessary dependencies, as well as the `packed_ensemble` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cross validation on hyperparameters of the model defined by ``param_grid``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1701507256997,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "ae107VZzmG7E",
    "ExecuteTime": {
     "end_time": "2023-12-20T17:05:49.436303700Z",
     "start_time": "2023-12-20T17:05:49.430608900Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_sizes': [(48, 128, 48), (128, 256, 128)],\n",
    "    'dropout': [True, False],\n",
    "    \"alpha\": [2, 4],\n",
    "    \"gamma\": [2, 4],\n",
    "    \"M\": [4],\n",
    "    'lr': [1e-2, 1e-3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The `param_grid` will be divided in 3 partitions, each one will be executed on a different machine.\n",
    "\n",
    "- Anton - partition 0\n",
    "- Anthony - partition 1\n",
    "- Alexi - partition 2\n",
    "\n",
    "Change it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partition = 1\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# hyperparameter tuning using CV\n",
    "hyperparameters_tuning(benchmark=benchmark, param_grid=param_grid, k_folds=4, num_epochs=100, batch_size=500000, shuffle=True, n_workers=6,\n",
    "                        scaler=StandardScaler(), partition=partition, verbose=True, size_scale=0.3, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cse1Puv6mG7F"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input and output sizes of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:24.132223400Z",
     "start_time": "2023-11-28T21:22:23.218956800Z"
    },
    "id": "U-hVXoVPmG7F"
   },
   "outputs": [],
   "source": [
    "input_size, output_size = infer_input_output_size(benchmark.train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a Packed MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:26.041921400Z",
     "start_time": "2023-11-28T21:22:25.989340700Z"
    },
    "id": "M6TL7FmFmG7F"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PackedMLP(input_size=input_size,\n",
    "                  output_size=output_size,\n",
    "                  hidden_sizes=(50, 100, 50),\n",
    "                  activation=F.relu,\n",
    "                  device=device,\n",
    "                  dropout=True,\n",
    "                  )\n",
    "model.to(device)\n",
    "print(model.device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `trainloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = model.process_dataset(benchmark.train_dataset, training=True, n_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:23:04.571539100Z",
     "start_time": "2023-11-28T21:22:46.174380400Z"
    },
    "id": "_-dtcqk8mG7G"
   },
   "outputs": [],
   "source": [
    "model, train_losses, _ = train(model, train_loader, epochs=1, device=device, lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_ctGjrHmG7G"
   },
   "source": [
    "##### prediction on `test_dataset`\n",
    "This dataset has the same distribution as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T15:25:11.456699Z",
     "start_time": "2023-11-28T15:25:11.456699Z"
    },
    "id": "-fssWxBHmG7G"
   },
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.457701800Z"
    },
    "id": "sNjmwJbfmG7G"
   },
   "outputs": [],
   "source": [
    "print(\"Prediction dimensions: \", predictions[\"x-velocity\"].shape, predictions[\"y-velocity\"].shape,\n",
    "      predictions[\"pressure\"].shape, predictions[\"turbulent_viscosity\"].shape)\n",
    "print(\"Observation dimensions:\", observations[\"x-velocity\"].shape, observations[\"y-velocity\"].shape,\n",
    "      observations[\"pressure\"].shape, observations[\"turbulent_viscosity\"].shape)\n",
    "print(\"We have good dimensions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.459698900Z"
    },
    "id": "TFRk7TdYmG7G"
   },
   "outputs": [],
   "source": [
    "from lips.evaluation.airfrans_evaluation import AirfRANSEvaluation\n",
    "\n",
    "evaluator = AirfRANSEvaluation(config_path=BENCH_CONFIG_PATH,\n",
    "                               scenario=BENCHMARK_NAME,\n",
    "                               data_path=DIRECTORY_NAME,\n",
    "                               log_path=LOG_PATH)\n",
    "\n",
    "observation_metadata = benchmark._test_dataset.extra_data\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0VVE2XzmG7G"
   },
   "source": [
    "##### Prediction on `test_ood_dataset`\n",
    "This dataset has a different distribution in comparison to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.460698700Z"
    },
    "id": "Q5SxkfOUmG7H"
   },
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_ood_dataset, device=device)\n",
    "evaluator = AirfRANSEvaluation(config_path=BENCH_CONFIG_PATH,\n",
    "                               scenario=BENCHMARK_NAME,\n",
    "                               data_path=DIRECTORY_NAME,\n",
    "                               log_path=LOG_PATH)\n",
    "\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
