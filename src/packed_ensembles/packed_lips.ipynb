{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packed ensemble submission process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:25:53.997221600Z",
     "start_time": "2023-12-19T12:25:48.211731900Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lips import get_root_path\n",
    "from lips.dataset.scaler.standard_scaler import StandardScaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "from lips.dataset.airfransDataSet import download_data\n",
    "from lips.augmented_simulators.torch_simulator import TorchSimulator\n",
    "from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative\n",
    "\n",
    "from my_augmented_simulator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:25:54.013022400Z",
     "start_time": "2023-12-19T12:25:53.998103300Z"
    }
   },
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:25:54.033534200Z",
     "start_time": "2023-12-19T12:25:54.014022300Z"
    }
   },
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"..\", \"airfoilConfigurations\", \"benchmarks\",\n",
    "                                 \"confAirfoil.ini\")  #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = r\"config.ini\"  #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:25:54.046533700Z",
     "start_time": "2023-12-19T12:25:54.029532800Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:25:54.065533700Z",
     "start_time": "2023-12-19T12:25:54.045532700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the airfrans dataset as a benchmark object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    benchmark : AirfRANSBenchmark\n",
    "        The airfrans benchmark object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open('benchmark.pkl', 'rb') as f:\n",
    "            benchmark = pickle.load(f)\n",
    "    except:\n",
    "        benchmark = AirfRANSBenchmark(benchmark_path=DIRECTORY_NAME,\n",
    "                                    config_path=BENCH_CONFIG_PATH,\n",
    "                                    benchmark_name=BENCHMARK_NAME,\n",
    "                                    log_path=LOG_PATH)\n",
    "        benchmark.load(path=DIRECTORY_NAME)\n",
    "        with open('benchmark.pkl', 'wb') as f:\n",
    "            pickle.dump(benchmark, f)\n",
    "    \n",
    "    return benchmark\n",
    "\n",
    "#benchmark = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T12:25:54.075538100Z",
     "start_time": "2023-12-19T12:25:54.064533700Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate(config_names):\n",
    "    \"\"\"\n",
    "    Creates packed MLP models for each model defined by config_names, trains them and evaluates them on the test dataset.\n",
    "    The results are then saved in appropriate files (results + models).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config_names : list\n",
    "        List of the names of the configurations to be used for training the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        0 if we have successfully trained and evaluated the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    for config_name in config_names:\n",
    "        print(\"Config name : \", config_name)\n",
    "        print(\"loading data...\")\n",
    "        benchmark = load_dataset()\n",
    "\n",
    "        chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "        no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "        scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "\n",
    "        name = \"packed_mlp\"\n",
    "\n",
    "        print(\"defining model...\")\n",
    "        # PackedMLP model definition \n",
    "        torch_sim = TorchSimulator(name=name,\n",
    "                           model=PackedMLP,\n",
    "                           scaler=StandardScalerIterative,\n",
    "                           scalerParams=scalerParams,\n",
    "                           log_path=None,\n",
    "                           device=\"cuda:0\",\n",
    "                           seed=42,\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=\"Benchmark1\",\n",
    "                           sim_config_path=SIM_CONFIG_PATH,\n",
    "                           sim_config_name=config_name,\n",
    "                          )\n",
    "        \n",
    "        print(\"training...\")\n",
    "        # model training \n",
    "        start = time.perf_counter()\n",
    "        torch_sim.train(benchmark.train_dataset, \n",
    "                save_path=None,\n",
    "                pin_memory=True, \n",
    "                non_blocking=True, \n",
    "                num_workers=6\n",
    "                )\n",
    "        end = time.perf_counter()\n",
    "        train_time = end-start\n",
    "        \n",
    "        print(\"saving model...\")\n",
    "        # saving the model \n",
    "        torch_sim.save(path=\"./models_new\")\n",
    "\n",
    "        print(\"evaluating model...\")\n",
    "        # evaluating the model \n",
    "        start = time.perf_counter()\n",
    "        torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                  eval_batch_size=256000,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=\"./evaluations\",\n",
    "                                                  save_predictions=True\n",
    "                                                 )\n",
    "        end = time.perf_counter()\n",
    "        evaluation_time = end-start\n",
    "        \n",
    "        # save the evaluation time to file\n",
    "        with open(f\"evaluations/{name}_{config_name}/time.txt\", \"a\") as f:\n",
    "            f.write(f\"Training took {train_time:.2f} seconds\\n\")\n",
    "            f.write(f\"Evaluation took {evaluation_time:.2f} seconds\")\n",
    "        \n",
    "        del benchmark\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config name :  DEEP_SMALL_A6_DECAY\n",
      "loading data...\n",
      "defining model...\n",
      "training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m config_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEEP_SMALL_A6_DECAY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEEP_SMALL_A8_DECAY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 46\u001b[0m, in \u001b[0;36msimulate\u001b[1;34m(config_names)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# model training \u001b[39;00m\n\u001b[0;32m     45\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 46\u001b[0m \u001b[43mtorch_sim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     53\u001b[0m train_time \u001b[38;5;241m=\u001b[39m end\u001b[38;5;241m-\u001b[39mstart\n",
      "File \u001b[1;32mc:\\Users\\antho\\.conda\\envs\\ml4science\\lib\\site-packages\\lips\\augmented_simulators\\torch_simulator.py:148\u001b[0m, in \u001b[0;36mTorchSimulator.train\u001b[1;34m(self, train_dataset, val_dataset, save_path, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m#losses, elapsed_time = train_model(self.model, data_loaders=data)\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m#pbar = tqdm(range(1, self.params[\"epochs\"]+1))\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m#for epoch in pbar:\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m#pbar.set_description(\"Epoch %s\" % str(epoch))\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     train_loss_epoch, train_metrics_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_one_epoch(epoch, train_loader, optimizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_losses\u001b[38;5;241m.\u001b[39mappend(train_loss_epoch)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nm_, arr_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\antho\\.conda\\envs\\ml4science\\lib\\site-packages\\lips\\augmented_simulators\\torch_simulator.py:196\u001b[0m, in \u001b[0;36mTorchSimulator._train_one_epoch\u001b[1;34m(self, epoch, train_loader, optimizer, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m         metric_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mget_loss_func(loss_name\u001b[38;5;241m=\u001b[39mmetric, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m         metric_value \u001b[38;5;241m=\u001b[39m metric_func(prediction, target)\n\u001b[1;32m--> 196\u001b[0m         metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(target)\n\u001b[0;32m    197\u001b[0m         metric_dict[metric] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m metric_value\n\u001b[0;32m    199\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config_names = [\"DEEP_SMALL_A6_DECAY\", \"DEEP_SMALL_A8_DECAY\"]\n",
    "simulate(config_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
