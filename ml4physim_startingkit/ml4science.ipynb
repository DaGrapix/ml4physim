{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packed Ensemble Application to the AirfRANS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the LIPS framework if it is not already done. For more information look at the LIPS framework [Github repository](https://github.com/IRT-SystemX/LIPS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:04.318752700Z",
     "start_time": "2023-11-29T19:12:04.196773800Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# or \n",
    "# !pip install -U ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the AirfRANS package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:04.318752700Z",
     "start_time": "2023-11-29T19:12:04.210800600Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install airfrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:04.319753800Z",
     "start_time": "2023-11-29T19:12:04.222321Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from lips import get_root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:04.319753800Z",
     "start_time": "2023-11-29T19:12:04.231836400Z"
    }
   },
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../ml4physim_startingkit/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:04.319753800Z",
     "start_time": "2023-11-29T19:12:04.243872100Z"
    }
   },
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"benchmarks\",\n",
    "                                 \"confAirfoil.ini\")  #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"simulators\", \"torch_fc.ini\")  #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:06.043774500Z",
     "start_time": "2023-11-29T19:12:04.255905100Z"
    }
   },
   "outputs": [],
   "source": [
    "from lips.dataset.airfransDataSet import download_data\n",
    "\n",
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-29T19:12:06.047785600Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open('benchmark.pkl', 'rb') as f:\n",
    "        benchmark = pickle.load(f)\n",
    "except:\n",
    "    benchmark = AirfRANSBenchmark(benchmark_path=DIRECTORY_NAME,\n",
    "                                config_path=BENCH_CONFIG_PATH,\n",
    "                                benchmark_name=BENCHMARK_NAME,\n",
    "                                log_path=LOG_PATH)\n",
    "    benchmark.load(path=DIRECTORY_NAME)\n",
    "    with open('benchmark.pkl', 'wb') as f:\n",
    "        pickle.dump(benchmark, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model selection (Cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary dependencies, as well as the `packed_ensemble` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import itertools as it\n",
    "\n",
    "from packed_ensembles import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:24:54.482164600Z",
     "start_time": "2023-11-29T15:24:54.466167Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_k_indices(num_row, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_row : int\n",
    "        Number of rows in the dataset.\n",
    "    k_fold : int\n",
    "        Number of folds\n",
    "    seed : int\n",
    "        Seed for random generator\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    k_indices : np.array\n",
    "        Array of indices for each fold\"\"\"\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create cross validation on hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:43:26.527546400Z",
     "start_time": "2023-11-29T15:43:26.493488100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hyperparameters_tuning(param_grid: dict, k_folds: int, num_epochs: int, batch_size: int = 128000,\n",
    "                            shuffle: bool = False, n_workers: int = 0, seed: int=42):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter tuning using K-fold cross validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param_grid : dict\n",
    "        Dictionary containing the values for each hyperparameter to be tested.\n",
    "    k_folds : int\n",
    "        Number of folds to be used in the cross validation.\n",
    "    num_epochs : int\n",
    "        Number of epochs to be used in the training.\n",
    "    batch_size : int\n",
    "        Batch size to be used in the training.\n",
    "    shuffle : bool\n",
    "        Whether to shuffle the training dataset.\n",
    "    n_workers : int\n",
    "        Number of workers to be used in the training.\n",
    "    seed : int\n",
    "        Random seed to be used in the training.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame containing the results of the hyperparameter tuning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate all combinations of parameter values\n",
    "    combinations = it.product(*(param_grid[key] for key in param_grid))\n",
    "\n",
    "    # Create a new dictionary with keys as hyperparameter names and values as lists of combinations\n",
    "    hyperparameter_dict = {key: [] for key in param_grid}\n",
    "\n",
    "    # Fill in the values for each key in the new dictionary\n",
    "    for combo in combinations:\n",
    "        for i, key in enumerate(param_grid):\n",
    "            hyperparameter_dict[key].append(combo[i])\n",
    "\n",
    "    hyperparameters_size = len(hyperparameter_dict[list(hyperparameter_dict.keys())[0]])\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = benchmark.train_dataset\n",
    "    input_size, output_size = infer_input_output_size(dataset)\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[*param_grid.keys(), \"mean_loss\"])\n",
    "\n",
    "    for i in tqdm(range(hyperparameters_size)):\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "\n",
    "        # Define the K-fold Cross Validator\n",
    "        k_indices = build_k_indices(extract_y.shape[0], k_folds, seed=seed)\n",
    "        summed_total_loss = 0\n",
    "\n",
    "        # K-fold Cross Validation model evaluation\n",
    "        for fold in range(k_folds):\n",
    "            val_ids = k_indices[fold]\n",
    "            train_ids = k_indices[~(np.arange(k_indices.shape[0]) == fold)]\n",
    "\n",
    "            train_x = extract_x[train_ids]\n",
    "            train_y = extract_y[train_ids]\n",
    "\n",
    "            train_x = train_x.reshape(train_x.shape[0] * train_x.shape[1], -1)\n",
    "            train_y = train_y.reshape(train_y.shape[0] * train_y.shape[1], -1)\n",
    "\n",
    "            val_x = extract_x[val_ids]\n",
    "            val_y = extract_y[val_ids]\n",
    "\n",
    "            train_dataset = TensorDataset(torch.from_numpy(train_x).float(), torch.from_numpy(train_y).float())\n",
    "            trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=n_workers)\n",
    "\n",
    "            val_dataset = TensorDataset(torch.from_numpy(val_x).float(), torch.from_numpy(val_y).float())\n",
    "            validateloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=n_workers)\n",
    "\n",
    "            # Init the neural network\n",
    "            model = PackedMLP(\n",
    "                input_size=input_size,\n",
    "                output_size=output_size,\n",
    "                hidden_sizes=hyperparameter_dict[\"hidden_sizes\"][i],\n",
    "                activation=F.relu,\n",
    "                device=device,\n",
    "                dropout=hyperparameter_dict[\"dropout\"][i],\n",
    "                M=hyperparameter_dict[\"M\"][i],\n",
    "                alpha=hyperparameter_dict[\"alpha\"][i],\n",
    "                gamma=hyperparameter_dict[\"gamma\"][i],\n",
    "            )\n",
    "            model.to(device)\n",
    "\n",
    "            model, _, _ = train(model, trainloader, epochs=num_epochs, device=device, lr=hyperparameter_dict[\"lr\"][i])\n",
    "\n",
    "            mean_loss = validate(model, validateloader, device)\n",
    "\n",
    "            summed_total_loss += mean_loss\n",
    "\n",
    "        mean_total_loss = summed_total_loss / k_folds\n",
    "        # Print fold results\n",
    "        print(f'{k_folds}-FOLD CROSS VALIDATION RESULTS FOR {i}th HYPERPARAMETERS')\n",
    "        print(f'Average: {mean_total_loss}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        new_row = {\n",
    "            'hidden_sizes': hyperparameter_dict[\"hidden_sizes\"][i],\n",
    "            'dropout': hyperparameter_dict[\"dropout\"][i],\n",
    "            'M': hyperparameter_dict[\"M\"][i],\n",
    "            'alpha': hyperparameter_dict[\"alpha\"][i],\n",
    "            'gamma': hyperparameter_dict[\"gamma\"][i],\n",
    "            'lr': hyperparameter_dict[\"lr\"][i],\n",
    "            'mean_loss': mean_total_loss\n",
    "        }\n",
    "        results_df.loc[len(results_df)] = new_row\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:39:10.229068Z",
     "start_time": "2023-11-29T15:39:10.214595Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_sizes': [(48, 128, 48), (128, 256, 128), (256, 512, 256)],\n",
    "    'dropout': [True, False],\n",
    "    \"alpha\": [2, 4],\n",
    "    \"gamma\": [1, 2, 4],\n",
    "    \"M\": [4],\n",
    "    'lr': [3e-4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_sizes': [(48, 128, 48)],\n",
    "    'dropout': [True],\n",
    "    \"alpha\": [2],\n",
    "    \"gamma\": [1],\n",
    "    \"M\": [4],\n",
    "    'lr': [3e-4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:46:02.828363500Z",
     "start_time": "2023-11-29T15:45:32.271700800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:58<00:00, 178.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-FOLD CROSS VALIDATION RESULTS FOR 0th HYPERPARAMETERS\n",
      "Average: 1499815.3429213779\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = hyperparameters_tuning(param_grid, k_folds=5, num_epochs=1, batch_size=128000, shuffle=True, n_workers=6)\n",
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:24.132223400Z",
     "start_time": "2023-11-28T21:22:23.218956800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = process_dataset(benchmark.train_dataset, training=True, n_workers=6)\n",
    "input_size, output_size = infer_input_output_size(benchmark.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:26.041921400Z",
     "start_time": "2023-11-28T21:22:25.989340700Z"
    }
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PackedMLP(input_size=input_size,\n",
    "                  output_size=output_size,\n",
    "                  hidden_sizes=(50, 100, 50),\n",
    "                  activation=F.relu,\n",
    "                  device=device,\n",
    "                  dropout=True,\n",
    "                  )\n",
    "model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:31.445847900Z",
     "start_time": "2023-11-28T21:22:31.411243900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:23:04.571539100Z",
     "start_time": "2023-11-28T21:22:46.174380400Z"
    }
   },
   "outputs": [],
   "source": [
    "model, train_losses, _ = train(model, train_loader, epochs=1, device=device, lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction on `test_dataset`\n",
    "This dataset has the same distribution as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T15:25:11.456699Z",
     "start_time": "2023-11-28T15:25:11.456699Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.457701800Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Prediction dimensions: \", predictions[\"x-velocity\"].shape, predictions[\"y-velocity\"].shape,\n",
    "      predictions[\"pressure\"].shape, predictions[\"turbulent_viscosity\"].shape)\n",
    "print(\"Observation dimensions:\", observations[\"x-velocity\"].shape, observations[\"y-velocity\"].shape,\n",
    "      observations[\"pressure\"].shape, observations[\"turbulent_viscosity\"].shape)\n",
    "print(\"We have good dimensions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.459698900Z"
    }
   },
   "outputs": [],
   "source": [
    "from lips.evaluation.airfrans_evaluation import AirfRANSEvaluation\n",
    "\n",
    "evaluator = AirfRANSEvaluation(config_path=BENCH_CONFIG_PATH,\n",
    "                               scenario=BENCHMARK_NAME,\n",
    "                               data_path=DIRECTORY_NAME,\n",
    "                               log_path=LOG_PATH)\n",
    "\n",
    "observation_metadata = benchmark._test_dataset.extra_data\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on `test_ood_dataset`\n",
    "This dataset has a different distribution in comparison to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.460698700Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_ood_dataset, device=device)\n",
    "evaluator = AirfRANSEvaluation(config_path=BENCH_CONFIG_PATH,\n",
    "                               scenario=BENCHMARK_NAME,\n",
    "                               data_path=DIRECTORY_NAME,\n",
    "                               log_path=LOG_PATH)\n",
    "\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
