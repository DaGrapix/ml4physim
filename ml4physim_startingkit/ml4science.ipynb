{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsOvkQ_CmG6z"
   },
   "source": [
    "# Packed Ensemble Application to the AirfRANS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `colab` to `True` if you wish to use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2228,
     "status": "ok",
     "timestamp": 1701505614095,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "0rUcVZoTmI7A",
    "outputId": "25da29da-fbb4-40e5-b2a7-1e0c04edd420",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:17.410738800Z",
     "start_time": "2023-12-03T21:24:17.316726300Z"
    }
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    !source/content/drive/MyDrive/my_colab_env/bin/activate\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    sys.path.append(\"/content/drive/MyDrive/my_colab_env/lib/python3.10/site-packages\")\n",
    "    os.chdir(\"/content/drive/MyDrive/ml4science/ml4physim_startingkit\")\n",
    "\n",
    "    sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQWKckDomG65"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrkPT3UcmG66"
   },
   "source": [
    "Install the LIPS framework if it is not already done. For more information look at the LIPS framework [Github repository](https://github.com/IRT-SystemX/LIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701505615102,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "g54uEia8mG67",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:17.411738500Z",
     "start_time": "2023-12-03T21:24:17.332244Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# or\n",
    "# !pip install -U ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD9DFGIamG69"
   },
   "source": [
    "\n",
    "Install the AirfRANS package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1701505621668,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "DUEm2XlhmG69",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:17.412740300Z",
     "start_time": "2023-12-03T21:24:17.348288700Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install airfrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:25.424536200Z",
     "start_time": "2023-12-03T21:24:17.367362Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lips import get_root_path\n",
    "from lips.dataset.scaler.standard_scaler import StandardScaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "from lips.dataset.airfransDataSet import download_data\n",
    "\n",
    "from my_packed_ensemble import *\n",
    "from my_packed_cv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDNZhB1tmG6-"
   },
   "source": [
    "## Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701505622617,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "23XBnSjnmG6_",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:25.441553300Z",
     "start_time": "2023-12-03T21:24:25.429061300Z"
    }
   },
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../ml4physim_startingkit/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzJsnBWRmG6_"
   },
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701505623020,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "fZ9nrutLmG7A",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:25.453621200Z",
     "start_time": "2023-12-03T21:24:25.442555300Z"
    }
   },
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"benchmarks\",\n",
    "                                 \"confAirfoil.ini\")  #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"simulators\", \"torch_fc.ini\")  #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qovzIDjOmG7A"
   },
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2186,
     "status": "ok",
     "timestamp": 1701505627135,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "TIo_MeNVmG7B",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:24:25.469020300Z",
     "start_time": "2023-12-03T21:24:25.456641500Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tWfcbpNmG7B"
   },
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20655,
     "status": "ok",
     "timestamp": 1701505649736,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "cZujz-mpmG7B",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:25:12.138403500Z",
     "start_time": "2023-12-03T21:24:25.473018300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets\n",
    "try:\n",
    "    with open('benchmark.pkl', 'rb') as f:\n",
    "        benchmark = pickle.load(f)\n",
    "except:\n",
    "    benchmark = AirfRANSBenchmark(benchmark_path=DIRECTORY_NAME,\n",
    "                                  config_path=BENCH_CONFIG_PATH,\n",
    "                                  benchmark_name=BENCHMARK_NAME,\n",
    "                                  log_path=LOG_PATH)\n",
    "    benchmark.load(path=DIRECTORY_NAME)\n",
    "    with open('benchmark.pkl', 'wb') as f:\n",
    "        pickle.dump(benchmark, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "0zh_rdsXmG7C"
   },
   "source": [
    "## Model selection (Cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmjFPEN9mG7C"
   },
   "source": [
    "Importing the necessary dependencies, as well as the `packed_ensemble` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cross validation on hyperparameters of the model defined by ``param_grid``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1701507256997,
     "user": {
      "displayName": "Alexi Semiz",
      "userId": "03762052284520431505"
     },
     "user_tz": -60
    },
    "id": "ae107VZzmG7E",
    "ExecuteTime": {
     "end_time": "2023-12-03T21:25:12.154073900Z",
     "start_time": "2023-12-03T21:25:12.147689400Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_sizes': [(48, 128, 48), (128, 256, 128)],\n",
    "    'dropout': [True, False],\n",
    "    \"alpha\": [2, 4],\n",
    "    \"gamma\": [2, 4],\n",
    "    \"M\": [4],\n",
    "    'lr': [1e-2, 1e-3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The `param_grid` will be divided in 3 partitions, each one will be executed on a different machine.\n",
    "\n",
    "- Anton - partition 0\n",
    "- Anthony - partition 1\n",
    "- Alexi - partition 2\n",
    "\n",
    "Change it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-03T21:25:12.155080300Z"
    }
   },
   "outputs": [],
   "source": [
    "partition = 0\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# hyperparameter tuning using CV\n",
    "hyperparameters_tuning(benchmark=benchmark, param_grid=param_grid, k_folds=4, num_epochs=100, batch_size=1280000, shuffle=True, n_workers=6,\n",
    "                        scaler=StandardScaler(), partition=partition, verbose=False, size_scale=0.3, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cse1Puv6mG7F"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:24.132223400Z",
     "start_time": "2023-11-28T21:22:23.218956800Z"
    },
    "id": "U-hVXoVPmG7F"
   },
   "outputs": [],
   "source": [
    "input_size, output_size = infer_input_output_size(benchmark.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:26.041921400Z",
     "start_time": "2023-11-28T21:22:25.989340700Z"
    },
    "id": "M6TL7FmFmG7F"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PackedMLP(input_size=input_size,\n",
    "                  output_size=output_size,\n",
    "                  hidden_sizes=(50, 100, 50),\n",
    "                  activation=F.relu,\n",
    "                  device=device,\n",
    "                  dropout=True,\n",
    "                  )\n",
    "model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = model.process_dataset(benchmark.train_dataset, training=True, n_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:22:31.445847900Z",
     "start_time": "2023-11-28T21:22:31.411243900Z"
    },
    "id": "TOtho6vhmG7F"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:23:04.571539100Z",
     "start_time": "2023-11-28T21:22:46.174380400Z"
    },
    "id": "_-dtcqk8mG7G"
   },
   "outputs": [],
   "source": [
    "model, train_losses, _ = train(model, train_loader, epochs=1, device=device, lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_ctGjrHmG7G"
   },
   "source": [
    "##### prediction on `test_dataset`\n",
    "This dataset has the same distribution as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T15:25:11.456699Z",
     "start_time": "2023-11-28T15:25:11.456699Z"
    },
    "id": "-fssWxBHmG7G"
   },
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.457701800Z"
    },
    "id": "sNjmwJbfmG7G"
   },
   "outputs": [],
   "source": [
    "print(\"Prediction dimensions: \", predictions[\"x-velocity\"].shape, predictions[\"y-velocity\"].shape,\n",
    "      predictions[\"pressure\"].shape, predictions[\"turbulent_viscosity\"].shape)\n",
    "print(\"Observation dimensions:\", observations[\"x-velocity\"].shape, observations[\"y-velocity\"].shape,\n",
    "      observations[\"pressure\"].shape, observations[\"turbulent_viscosity\"].shape)\n",
    "print(\"We have good dimensions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.459698900Z"
    },
    "id": "TFRk7TdYmG7G"
   },
   "outputs": [],
   "source": [
    "from lips.evaluation.airfrans_evaluation import AirfRANSEvaluation\n",
    "\n",
    "evaluator = AirfRANSEvaluation(config_path=BENCH_CONFIG_PATH,\n",
    "                               scenario=BENCHMARK_NAME,\n",
    "                               data_path=DIRECTORY_NAME,\n",
    "                               log_path=LOG_PATH)\n",
    "\n",
    "observation_metadata = benchmark._test_dataset.extra_data\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0VVE2XzmG7G"
   },
   "source": [
    "##### Prediction on `test_ood_dataset`\n",
    "This dataset has a different distribution in comparison to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T15:25:11.460698700Z"
    },
    "id": "Q5SxkfOUmG7H"
   },
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_ood_dataset, device=device)\n",
    "evaluator = AirfRANSEvaluation(config_path=BENCH_CONFIG_PATH,\n",
    "                               scenario=BENCHMARK_NAME,\n",
    "                               data_path=DIRECTORY_NAME,\n",
    "                               log_path=LOG_PATH)\n",
    "\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
