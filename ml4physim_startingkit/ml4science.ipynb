{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packed Ensemble Application to the AirfRANS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the LIPS framework if it is not already done. For more information look at the LIPS framework [Github repository](https://github.com/IRT-SystemX/LIPS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# or \n",
    "# !pip install -U ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the AirfRANS package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install airfrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lips import get_root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../ml4physim_startingkit/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\",\"benchmarks\",\"confAirfoil.ini\") #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = os.path.join(\"airfoilConfigurations\",\"simulators\",\"torch_fc.ini\") #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.dataset.airfransDataSet import download_data\n",
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset (task: scarce, split: train): 100%|██████████| 200/200 [00:45<00:00,  4.43it/s]\n",
      "Loading dataset (task: full, split: test): 100%|██████████| 200/200 [00:47<00:00,  4.22it/s]\n",
      "Loading dataset (task: reynolds, split: test): 100%|██████████| 496/496 [01:56<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the required benchmark datasets\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "\n",
    "benchmark=AirfRANSBenchmark(benchmark_path = DIRECTORY_NAME,\n",
    "                            config_path = BENCH_CONFIG_PATH,\n",
    "                            benchmark_name = BENCHMARK_NAME,\n",
    "                            log_path = LOG_PATH)\n",
    "benchmark.load(path=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple Packed MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 1: Architecture implementation using the ``torch-uncertainty`` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torch_uncertainty.layers import PackedLinear\n",
    "\n",
    "class PackedMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple MLP with packed layers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str (default: \"PackedMLP\")\n",
    "        The name of the model\n",
    "    input_size: int (default: None)\n",
    "        The size of the input\n",
    "    output_size: int (default: None)\n",
    "        The size of the output\n",
    "    hidden_sizes: tuple (default: (100, 100,))\n",
    "        The sizes of the hidden layers\n",
    "    activation: torch.nn.functional (default: F.relu)\n",
    "        The activation function\n",
    "    dropout: bool (default: False)\n",
    "        Whether to use dropout\n",
    "    batch_normalization: bool (default: False)\n",
    "        Whether to use batch normalization\n",
    "    M: int (default: 4)\n",
    "        The number of estimators\n",
    "    alpha: int (default: 2)\n",
    "        The alpha parameter\n",
    "    gamma: int (default: 1)\n",
    "        The gamma parameter\n",
    "    device: str (default: \"cpu\")\n",
    "        The device to use\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 name: str=\"PackedMLP\",\n",
    "                 input_size: int=None,\n",
    "                 output_size: int=None,\n",
    "                 hidden_sizes: tuple=(100, 100,),\n",
    "                 activation=F.relu,\n",
    "                 dropout: bool=False,\n",
    "                 M: int=4,\n",
    "                 alpha: int=2,\n",
    "                 gamma: int=1,\n",
    "                 device: str=\"cpu\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=0.2)\n",
    "        else:\n",
    "            self.dropout = nn.Identity()\n",
    "\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        self.num_estimators = M\n",
    "\n",
    "        self.input_layer = PackedLinear(self.input_size, self.hidden_sizes[0], alpha=alpha, num_estimators=M, gamma=gamma, first=True,\n",
    "                                        device=device)\n",
    "        self.hidden_layers = nn.ModuleList([PackedLinear(in_f, out_f, alpha=alpha, num_estimators=M, gamma=gamma, device=device) \\\n",
    "                                           for in_f, out_f in zip(self.hidden_sizes[:-1], self.hidden_sizes[1:])])\n",
    "        self.output_layer = PackedLinear(self.hidden_sizes[-1], self.output_size, alpha=alpha, num_estimators=M, gamma=gamma, last=True,\n",
    "                                         device=device)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        The forward pass of the model\n",
    "        \"\"\"\n",
    "        out = self.input_layer(data)\n",
    "        for _, fc_ in enumerate(self.hidden_layers):\n",
    "            out = fc_(out)\n",
    "            out = self.activation(out)\n",
    "            out = self.dropout(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 2: Process the data to acquire the right Inputs and Outputs for the model alongside their dimensions\n",
    "This function uses a functionality offered by the Dataset class to extract the required inputs and outputs for the problem in hand, which facilitate the task. \n",
    "\n",
    "It also allows to create DataLoader from existing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, batch_size: int=128000, training: bool=False, shuffle: bool=False, n_workers: int=0):\n",
    "    if training:\n",
    "        batch_size = batch_size\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "    else:\n",
    "        batch_size = batch_size\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "\n",
    "    torch_dataset = TensorDataset(torch.from_numpy(extract_x).float(), torch.from_numpy(extract_y).float())\n",
    "    data_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=n_workers)\n",
    "    return data_loader\n",
    "\n",
    "def infer_input_output_size(dataset):\n",
    "    *dim_inputs, output_size = dataset.get_sizes()\n",
    "    input_size = np.sum(dim_inputs)\n",
    "    return input_size, output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 3: Implementation of the Training, Validation and Prediction functions\n",
    "\n",
    "**train.** This function allows to train (adjust the parameters of) your defined model using the provided datasets.\n",
    "\n",
    "**validate.** This function allows to validate your model on a validation dataset. The validation step is not mendatory and is used only to trace the model behavior (overfitting or not). \n",
    "\n",
    "**predict.** This function allows to predict using the trained model. The `DataSet` class provides a function `reconstruct_output` which allows to reshape the predictions in the correct form which will be comparable with ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "def train(model, train_loader, val_loader=None, epochs=100, lr=3e-4, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # select your optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # select your loss function\n",
    "    loss_function = nn.MSELoss()\n",
    "    pbar = tqdm(range(epochs), desc=\"Epochs\")\n",
    "    for epoch in pbar:\n",
    "        # set your model for training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        # iterate over the batches of data\n",
    "        pbar_batch=tqdm(train_loader)\n",
    "        for batch in pbar_batch:\n",
    "            data, target = batch\n",
    "            # transfer your data on proper device. The model and your data should be on the same device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # predict using your model on the current batch of data\n",
    "            prediction = model(data)\n",
    "            # compute the loss between prediction and real target, by repeating the target so it fits the different estimators \n",
    "            loss = loss_function(prediction, target.repeat(model.num_estimators, 1))\n",
    "            # compute the gradient (backward pass of back propagation algorithm)\n",
    "            loss.backward()\n",
    "            # update the parameters of your model\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * len(data)\n",
    "        # the validation step is optional\n",
    "        if val_loader is not None:\n",
    "            val_loss = validate(model, val_loader, device)\n",
    "            val_losses.append(val_loss)\n",
    "        mean_loss = total_loss / len(train_loader.dataset)\n",
    "        print(f\"Train Epoch: {epoch}   Avg_Loss: {mean_loss:.5f}\")\n",
    "        train_losses.append(mean_loss)\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    # set the model for evaluation (no update of the parameters)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    loss_function = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        pbar_batch=tqdm(val_loader)\n",
    "        for batch in val_loader:\n",
    "            data, target = batch\n",
    "            data.to(device)\n",
    "            target.to(device)\n",
    "            prediction = model(data)\n",
    "            loss = loss_function(prediction, target)\n",
    "            total_loss += loss.item()*len(data)\n",
    "        mean_loss = total_loss / len(val_loader.dataset)\n",
    "        print(f\"Eval:   Avg_Loss: {mean_loss:.5f}\")\n",
    "    return mean_loss\n",
    "\n",
    "def predict(model, dataset, device):\n",
    "    # set the model for the evaluation\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    observations = []\n",
    "    test_loader = process_dataset(dataset, training=False, shuffle=False)\n",
    "    # we dont require the computation of the gradient\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            data, target = batch\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            prediction = model(data)\n",
    "            \n",
    "            #averaging the predictions of the different ensemble models\n",
    "            packed_split = rearrange(prediction, '(n b) m -> b n m', n=model.num_estimators)\n",
    "            packed_prediction = packed_split.mean(dim=1)\n",
    "\n",
    "            if device == torch.device(\"cpu\"):\n",
    "                predictions.append(packed_prediction.numpy())\n",
    "                observations.append(target.numpy())\n",
    "            else:\n",
    "                predictions.append(packed_prediction.cpu().data.numpy())\n",
    "                observations.append(target.cpu().data.numpy())\n",
    "    # reconstruct the prediction in the proper required shape of target variables\n",
    "    predictions = np.concatenate(predictions)\n",
    "    predictions = dataset.reconstruct_output(predictions)\n",
    "    # Do the same for the real observations\n",
    "    observations = np.concatenate(observations)\n",
    "    observations = dataset.reconstruct_output(observations)\n",
    "\n",
    "    return predictions, observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = process_dataset(benchmark.train_dataset, training=True, n_workers=6)\n",
    "input_size, output_size = infer_input_output_size(benchmark.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PackedMLP(input_size=input_size,\n",
    "                               output_size=output_size,\n",
    "                               hidden_sizes=(50,100,50),\n",
    "                               activation=F.relu,\n",
    "                               device=device,\n",
    "                               dropout=True,\n",
    "                               )\n",
    "model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedMLP(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (input_layer): PackedLinear(\n",
      "    (conv1x1): Conv1d(7, 100, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): PackedLinear(\n",
      "      (conv1x1): Conv1d(100, 200, kernel_size=(1,), stride=(1,), groups=4)\n",
      "    )\n",
      "    (1): PackedLinear(\n",
      "      (conv1x1): Conv1d(200, 100, kernel_size=(1,), stride=(1,), groups=4)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): PackedLinear(\n",
      "    (conv1x1): Conv1d(100, 16, kernel_size=(1,), stride=(1,), groups=4)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:30<00:00,  4.80it/s]\n",
      "Epochs: 100%|██████████| 1/1 [00:30<00:00, 30.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0   Avg_Loss: 1510000.78315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, _ = train(model, train_loader, epochs=1, device=device, lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction on `test_dataset`\n",
    "This dataset has the same distribution as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [04:21<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, observations = predict(model, benchmark._test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction dimensions:  (35849332,) (35849332,) (35849332,) (35849332,)\n",
      "Observation dimensions: (35849332,) (35849332,) (35849332,) (35849332,)\n",
      "We have good dimensions!\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction dimensions: \", predictions[\"x-velocity\"].shape, predictions[\"y-velocity\"].shape, predictions[\"pressure\"].shape, predictions[\"turbulent_viscosity\"].shape)\n",
    "print(\"Observation dimensions:\", observations[\"x-velocity\"].shape, observations[\"y-velocity\"].shape, observations[\"pressure\"].shape, observations[\"turbulent_viscosity\"].shape)\n",
    "print(\"We have good dimensions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 35849332 but corresponding boolean dimension is 18515415",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Desktop\\EPFL\\ML4Science\\ml4physim_startingkit\\ml4science.ipynb Cell 39\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m evaluator \u001b[39m=\u001b[39m AirfRANSEvaluation(config_path \u001b[39m=\u001b[39m BENCH_CONFIG_PATH,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                scenario \u001b[39m=\u001b[39m BENCHMARK_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                data_path \u001b[39m=\u001b[39m DIRECTORY_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                log_path \u001b[39m=\u001b[39m LOG_PATH)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m observation_metadata \u001b[39m=\u001b[39m benchmark\u001b[39m.\u001b[39mtrain_dataset\u001b[39m.\u001b[39mextra_data\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m metrics \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39;49mevaluate(observations\u001b[39m=\u001b[39;49mobservations,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                              predictions\u001b[39m=\u001b[39;49mpredictions,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                              observation_metadata\u001b[39m=\u001b[39;49mobservation_metadata)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/ml4science.ipynb#X63sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(metrics)\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\evaluation\\airfrans_evaluation.py:82\u001b[0m, in \u001b[0;36mAirfRANSEvaluation.evaluate\u001b[1;34m(self, observations, predictions, observation_metadata, save_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_metadata \u001b[39m=\u001b[39m observation_metadata\n\u001b[0;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dict\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_evaluation(cat)\n\u001b[0;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\evaluation\\airfrans_evaluation.py:100\u001b[0m, in \u001b[0;36mAirfRANSEvaluation._dispatch_evaluation\u001b[1;34m(self, category)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m category \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMACHINE_LEARNING:\n\u001b[0;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dict[category]:\n\u001b[1;32m--> 100\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_ml()\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m category \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPHYSICS_COMPLIANCES:\n\u001b[0;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dict[category]:\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\evaluation\\airfrans_evaluation.py:134\u001b[0m, in \u001b[0;36mAirfRANSEvaluation.evaluate_ml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m pred_pressure \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions[\u001b[39m\"\u001b[39m\u001b[39mpressure\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    133\u001b[0m surface_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_metadata[\u001b[39m\"\u001b[39m\u001b[39msurface\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 134\u001b[0m tmp_surface \u001b[39m=\u001b[39m metric_fun(true_pressure[surface_data\u001b[39m.\u001b[39;49mastype(\u001b[39mbool\u001b[39;49m)], pred_pressure[surface_data\u001b[39m.\u001b[39mastype(\u001b[39mbool\u001b[39m)])\n\u001b[0;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMACHINE_LEARNING][metric_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_surfacic\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mpressure\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(tmp)}\n\u001b[0;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m surfacic for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, metric_name, \u001b[39m\"\u001b[39m\u001b[39mpressure\u001b[39m\u001b[39m\"\u001b[39m, tmp_surface)\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 35849332 but corresponding boolean dimension is 18515415"
     ]
    }
   ],
   "source": [
    "from lips.evaluation.airfrans_evaluation import AirfRANSEvaluation\n",
    "\n",
    "evaluator = AirfRANSEvaluation(config_path = BENCH_CONFIG_PATH,\n",
    "                               scenario = BENCHMARK_NAME,\n",
    "                               data_path = DIRECTORY_NAME,\n",
    "                               log_path = LOG_PATH)\n",
    "\n",
    "observation_metadata = benchmark._test_dataset.extra_data\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on `test_ood_dataset`\n",
    "This dataset has a different distribution in comparison to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_ood_dataset, device=device)\n",
    "evaluator = AirfRANSEvaluation(config_path = BENCH_CONFIG_PATH,\n",
    "                               scenario = BENCHMARK_NAME,\n",
    "                               data_path = DIRECTORY_NAME,\n",
    "                               log_path = LOG_PATH)\n",
    "\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection (Cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cross validation on hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid of parameters using a logaritmic scale\n",
    "param_grid = {'lr': [3e-4],\n",
    "                'hidden_sizes': [(50, 100, 50), (100, 200, 100), (200, 400, 200)],\n",
    "                'dropout': [True, False]}\n",
    "\n",
    "hyperparameter_grid = [(hidden_layer_sizes, lr, dropout)\n",
    "                       for hidden_layer_sizes   in param_grid[\"hidden_sizes\"]\n",
    "                       for lr                   in param_grid[\"lr\"]\n",
    "                       for dropout              in param_grid[\"dropout\"]]\n",
    "\n",
    "for hyperparameter in tqdm(hyperparameter_grid):\n",
    "    model = PackedMLP(input_size=input_size,\n",
    "                                output_size=output_size,\n",
    "                                hidden_sizes=hyperparameter[0],\n",
    "                                activation=F.relu,\n",
    "                                device=device,\n",
    "                                dropout=hyperparameter[2],\n",
    "                                )\n",
    "    model.to(device)\n",
    "\n",
    "    #train using CV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to implement\"\"\"\n",
    "\n",
    "\n",
    "# Define the function to optimize the hyperparameters\n",
    "def optimize_hyperparameters(loss_fn, X_train, y_train, X_test, y_test, X_val, y_val, param_dist):\n",
    "    \"\"\"\n",
    "    Searches for the best hyperparameters, using a gridsearch approach\n",
    "    \"\"\"\n",
    "    best_validation_error = np.inf\n",
    "    best_hyperparameters = None\n",
    "\n",
    "    input_size  = X_train.shape[1]\n",
    "    output_size = y_train.shape[1]\n",
    "\n",
    "    hyperparameter_grid = [(hidden_layer_sizes, activation, lr, batch_size, n_epochs)\n",
    "                       for hidden_layer_sizes   in param_dist[\"hidden_layer_sizes\"]\n",
    "                       for activation           in param_dist[\"activation\"]\n",
    "                       for lr                   in param_dist[\"lr\"]\n",
    "                       for batch_size           in param_dist[\"batch_size\"]\n",
    "                       for n_epochs             in param_dist[\"n_epochs\"]]\n",
    "\n",
    "    n_total = len(hyperparameter_grid)\n",
    "    counter = 1\n",
    "\n",
    "    for hidden_layer_sizes, activation, lr, batch_size, n_epochs in hyperparameter_grid:\n",
    "        print(f\"\\nstep: {counter}/{n_total}\")\n",
    "        print(f\"hidden_layer_sizes: {hidden_layer_sizes}, activation:{activation}, lr{lr}, batch_size:{batch_size}, n_epochs:{n_epochs}\")\n",
    "\n",
    "        model = create_model(input_size, output_size, hidden_layer_sizes, activation)\n",
    "        train(model, X_train, X_test, y_train, y_test, lr, batch_size, n_epochs, loss_fn)\n",
    "\n",
    "        # Evaluate the best model on validation data\n",
    "        y_pred = model(X_val)\n",
    "        val_mse = loss_fn(y_val, y_pred)\n",
    "\n",
    "        if (val_mse < best_validation_error):\n",
    "            best_hyperparameters = [hidden_layer_sizes, activation, lr, batch_size, n_epochs]\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        training_error  = loss_fn(model(X_train), y_train)\n",
    "        test_error      = loss_fn(model(X_test), y_test)\n",
    "        val_error       = loss_fn(model(X_val), y_val)\n",
    "\n",
    "        print(f\"training error: {training_error} , test error: {test_error} , val error: {val_error}\")\n",
    "        counter += 1\n",
    "    \n",
    "    best_model = create_model(input_size, output_size, best_hyperparameters[0], best_hyperparameters[1])\n",
    "    return best_hyperparameters, best_model, best_validation_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
