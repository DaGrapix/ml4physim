{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packed ensemble submission process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:55:04.142992800Z",
     "start_time": "2023-12-16T16:54:57.089462900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lips import get_root_path\n",
    "from lips.dataset.scaler.standard_scaler import StandardScaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "from lips.dataset.airfransDataSet import download_data\n",
    "from lips.augmented_simulators.torch_simulator import TorchSimulator\n",
    "from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative\n",
    "\n",
    "#from my_custom_packed_ensemble import *\n",
    "#from my_packed_cv import *\n",
    "from my_augmented_simulator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:55:04.148993800Z",
     "start_time": "2023-12-16T16:55:04.143995400Z"
    }
   },
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../ml4physim_startingkit/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:55:04.158582300Z",
     "start_time": "2023-12-16T16:55:04.147993Z"
    }
   },
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"benchmarks\",\n",
    "                                 \"confAirfoil.ini\")  #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = r\"config.ini\"  #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:55:04.178275Z",
     "start_time": "2023-12-16T16:55:04.158582300Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:55:11.638617200Z",
     "start_time": "2023-12-16T16:55:04.174373600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the airfrans dataset as a benchmark object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    benchmark : AirfRANSBenchmark\n",
    "        The airfrans benchmark object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open('benchmark.pkl', 'rb') as f:\n",
    "            benchmark = pickle.load(f)\n",
    "    except:\n",
    "        benchmark = AirfRANSBenchmark(benchmark_path=DIRECTORY_NAME,\n",
    "                                    config_path=BENCH_CONFIG_PATH,\n",
    "                                    benchmark_name=BENCHMARK_NAME,\n",
    "                                    log_path=LOG_PATH)\n",
    "        benchmark.load(path=DIRECTORY_NAME)\n",
    "        with open('benchmark.pkl', 'wb') as f:\n",
    "            pickle.dump(benchmark, f)\n",
    "    \n",
    "    return benchmark\n",
    "\n",
    "benchmark = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Anthony : 0\n",
    "    Anton   : 1\n",
    "\"\"\"\n",
    "\n",
    "partition = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if partition == 0:  config_names = [\"SMOOTH_G4\", \"BIG_MODEL\"]\n",
    "else:               config_names = [\"DEFAULT\", \"SMOOTH_G1\", \"SMOOTH_G2\"]\n",
    "\n",
    "def simulate(config_names):\n",
    "    \"\"\"\n",
    "    Creates a packed MLP model, trains it and evaluates it on the test dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config_names : list\n",
    "        List of the names of the configurations to be used for training the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        0 if we have successfully trained and evaluated the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    for config_name in config_names:\n",
    "        benchmark = load_dataset()\n",
    "\n",
    "        chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "        no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "        scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "\n",
    "        # PackedMLP model definition \n",
    "        torch_sim = TorchSimulator(name=\"packed_mlp\",\n",
    "                           model=PackedMLP,\n",
    "                           scaler=StandardScalerIterative,\n",
    "                           scalerParams=scalerParams,\n",
    "                           log_path=None,\n",
    "                           device=\"cuda:0\",\n",
    "                           seed=42,\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=\"Benchmark1\",\n",
    "                           sim_config_path=SIM_CONFIG_PATH,\n",
    "                           sim_config_name=\"DEFAULT\",\n",
    "                          )\n",
    "        \n",
    "        # model training \n",
    "        torch_sim.train(benchmark.train_dataset, \n",
    "                save_path=None, \n",
    "                epochs=3, \n",
    "                train_batch_size=128000,\n",
    "                pin_memory=True, \n",
    "                non_blocking=True, \n",
    "                num_workers=6\n",
    "                )\n",
    "        \n",
    "        # saving the model \n",
    "        torch_sim.save()\n",
    "\n",
    "        # evaluating the model \n",
    "        torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                  eval_batch_size=256000,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=\".\",\n",
    "                                                  save_predictions=True\n",
    "                                                 )\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:55:11.656550400Z",
     "start_time": "2023-12-16T16:55:11.640617Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "\n",
    "torch_sim = TorchSimulator(name=\"packed_mlp\",\n",
    "                           model=PackedMLP,\n",
    "                           scaler=StandardScalerIterative,\n",
    "                           scalerParams=scalerParams,\n",
    "                           log_path=None,\n",
    "                           device=\"cuda:0\",\n",
    "                           seed=42,\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=\"Benchmark1\",\n",
    "                           sim_config_path=SIM_CONFIG_PATH,\n",
    "                           sim_config_name=\"DEFAULT\",\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T16:57:30.842892Z",
     "start_time": "2023-12-16T16:55:11.660562700Z"
    }
   },
   "outputs": [],
   "source": [
    "torch_sim.train(benchmark.train_dataset, \n",
    "                save_path=None, \n",
    "                epochs=3, \n",
    "                train_batch_size=128000,\n",
    "                pin_memory=True, \n",
    "                non_blocking=True, \n",
    "                num_workers=6\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T18:01:57.080670600Z",
     "start_time": "2023-12-16T16:57:30.837383800Z"
    }
   },
   "outputs": [],
   "source": [
    "torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                  eval_batch_size=256000,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=\".\",\n",
    "                                                  save_predictions=True\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T18:01:57.092737400Z",
     "start_time": "2023-12-16T18:01:57.088673100Z"
    }
   },
   "outputs": [],
   "source": [
    "torch_sim_metrics[\"test\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
