{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packed ensemble submission process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lips import get_root_path\n",
    "from lips.dataset.scaler.standard_scaler import StandardScaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "from lips.dataset.airfransDataSet import download_data\n",
    "from lips.augmented_simulators.torch_simulator import TorchSimulator\n",
    "from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative\n",
    "\n",
    "#from my_custom_packed_ensemble import *\n",
    "#from my_packed_cv import *\n",
    "from my_augmented_simulator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../ml4physim_startingkit/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\", \"benchmarks\",\n",
    "                                 \"confAirfoil.ini\")  #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = r\"config.ini\"  #Configuration file re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets\n",
    "try:\n",
    "    with open('benchmark.pkl', 'rb') as f:\n",
    "        benchmark = pickle.load(f)\n",
    "except:\n",
    "    benchmark = AirfRANSBenchmark(benchmark_path=DIRECTORY_NAME,\n",
    "                                  config_path=BENCH_CONFIG_PATH,\n",
    "                                  benchmark_name=BENCHMARK_NAME,\n",
    "                                  log_path=LOG_PATH)\n",
    "    benchmark.load(path=DIRECTORY_NAME)\n",
    "    with open('benchmark.pkl', 'wb') as f:\n",
    "        pickle.dump(benchmark, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "\n",
    "torch_sim = TorchSimulator(name=\"packed_mlp\",\n",
    "                           model=PackedMLP,\n",
    "                           scaler=StandardScalerIterative,\n",
    "                           scalerParams=scalerParams,\n",
    "                           log_path=None,\n",
    "                           device=\"cuda:0\",\n",
    "                           seed=42,\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=\"Benchmark1\",\n",
    "                           sim_config_path=SIM_CONFIG_PATH,\n",
    "                           sim_config_name=\"DEFAULT\",\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0   Avg_Loss: 0.32531 ['MAELoss: 0.28161']\n",
      "Train Epoch: 1   Avg_Loss: 0.17452 ['MAELoss: 0.19592']\n",
      "Train Epoch: 2   Avg_Loss: 0.15410 ['MAELoss: 0.18411']\n"
     ]
    }
   ],
   "source": [
    "torch_sim.train(benchmark.train_dataset, \n",
    "                save_path=None, \n",
    "                epochs=3, \n",
    "                train_batch_size=128000,\n",
    "                pin_memory=True, \n",
    "                non_blocking=True, \n",
    "                num_workers=6\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\benchmark\\airfransBenchmark.py:250: UserWarning: You indicate to save the predictions, without providing a path. No predictions will be saved!\n",
      "  warnings.warn(message=\"You indicate to save the predictions, without providing a path. No predictions will be saved!\")\n"
     ]
    }
   ],
   "source": [
    "torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                  eval_batch_size=256000,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=\".\",\n",
    "                                                  save_predictions=True\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics[\"test\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
