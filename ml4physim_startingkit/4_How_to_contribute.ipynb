{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Run of an Augmented Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial notebook provides a guidance for installing the required packages and testing implemented augmented simulators using LIPS platform. \n",
    "\n",
    "**A quick walkthrough:**\n",
    "\n",
    "- Install the required packages using the requirements.txt file in the github repository for the required used case.\n",
    "\n",
    "- Some baseline are already implemented in the LIPS platform that could be seen to have some inspiration.\n",
    "\n",
    "- The augmented simulators related hyperparameters could be modified via dedicated configuration files.\n",
    "\n",
    "- The LIPS platform will be used to evaluate the trained augmented simulators from different evaluation criteria categories and attribute a score to each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to implement your own augmented simulator\n",
    "\n",
    "In the following, we show 3 ways to implement an augmented simulator (based on ML or a hybrid physics-AI model):\n",
    "\n",
    "1- Using an existing augmented simulator (baseline) in LIPS platform, train it and then evaluate the results;\n",
    "\n",
    "2- Implement an augmented simulator using LIPS framework template to take the advantage of existing training loop and other offered features;\n",
    "\n",
    "3- Implement an augmented simulator independently from LIPS platform and plug the trained model into LIPS to evaluate its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As so, in order to adress the augmented simulator handling when running this notebook, it is divided into the following four sections:\n",
    "1. [Generic step (Load the required data)](#generic_step)\n",
    "2. [Evaluate an existing augmented simulator](#existing_sim) (Beginner users)\n",
    "3. [Train and evaluate a custom augmented simulators developed using LIPS framework](#train_using_lips) (Intermediate level users)\n",
    "4. [Train a custom augmented simulator independently from LIPS and use the framwork to evaluate the final results](#train_custom) (Advanced users)\n",
    "\n",
    "Depending on the user level, it conveniently point to the dedicated section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Step (Load the required data) <a id='generic_step'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the LIPS framework if it is not already done. For more information look at the LIPS framework [Github repository](https://github.com/IRT-SystemX/LIPS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# or \n",
    "# !pip install -U ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the AirfRANS package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install airfrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lips import get_root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = 'Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\antho\\\\miniconda3\\\\envs\\\\ml4science\\\\lib\\\\site-packages\\\\lips\\\\'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIPS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration files path, that aim to describe specific caracteristics of the use case or the augmented simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCH_CONFIG_PATH = os.path.join(\"airfoilConfigurations\",\"benchmarks\",\"confAirfoil.ini\") #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = os.path.join(\"airfoilConfigurations\",\"simulators\",\"torch_fc.ini\") #Configuration file re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airfoilConfigurations\\\\benchmarks\\\\confAirfoil.ini'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BENCH_CONFIG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.dataset.airfransDataSet import download_data\n",
    "if not os.path.isdir(DIRECTORY_NAME):\n",
    "    download_data(root_path=\".\", directory_name=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset using the dedicated class used by LIPS platform offers a list of advantages:\n",
    "\n",
    "1. Ease the importing of datasets\n",
    "1. A set of functions to organize the `inputs` and `outputs` required by augmented simulators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset (task: scarce, split: train): 100%|██████████| 200/200 [00:44<00:00,  4.47it/s]\n",
      "Loading dataset (task: full, split: test): 100%|██████████| 200/200 [00:43<00:00,  4.63it/s]\n",
      "Loading dataset (task: reynolds, split: test): 100%|██████████| 496/496 [01:48<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the required benchmark datasets\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "\n",
    "benchmark=AirfRANSBenchmark(benchmark_path = DIRECTORY_NAME,\n",
    "                            config_path = BENCH_CONFIG_PATH,\n",
    "                            benchmark_name = BENCHMARK_NAME,\n",
    "                            log_path = LOG_PATH)\n",
    "benchmark.load(path=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section-I (Evaluate an existing augmented simulator) <a id='existing_sim'></a>\n",
    "For beginners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing an architecture from exisiting set of architectures and instantiate the `TorchSimulator` class which offers a set of utilities to train and analyze the selected augmented simulator. User could play with the configuration file of an existing augmented simulator to modify the model hyperparameters.\n",
    "\n",
    "The configuration file could be found at `./configurations/airfoil/simulators/torch_fc.ini`:\n",
    "\n",
    "```output\n",
    "[DEFAULT]\n",
    "name = \"torch_fc\"\n",
    "layers = (64,64,8,64,64,64,8,64,64)\n",
    "activation = \"relu\"\n",
    "layer = \"linear\"\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "metrics = (\"MAELoss\",)\n",
    "loss = {\"name\": \"MSELoss\",\n",
    "        \"params\": {\"size_average\": None,\n",
    "                   \"reduce\": None,\n",
    "                   \"reduction\": 'mean'}}\n",
    "device = \"cpu\"\n",
    "optimizer = {\"name\": \"adam\",\n",
    "             \"params\": {\"lr\": 2e-4}}\n",
    "train_batch_size = 128000\n",
    "eval_batch_size = 256000\n",
    "epochs = 200\n",
    "shuffle = False\n",
    "save_freq = False\n",
    "ckpt_freq = 50\n",
    "```\n",
    "\n",
    "In the example below we select the configuration provided in `[DEFAULT]` section and new configuration could be created using a new section name and modifying the existing parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: In this context, `train_batch_size` and `eval_batch_size` refer to the number of nodes, not the number of simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to instantiate a simulator with the `[DEFAULT]` configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.torch_models.fully_connected import TorchFullyConnected\n",
    "from lips.augmented_simulators.torch_simulator import TorchSimulator\n",
    "from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative\n",
    "\n",
    "chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "\n",
    "torch_sim = TorchSimulator(name=\"torch_fc\",\n",
    "                           model=TorchFullyConnected,\n",
    "                           scaler=StandardScalerIterative,\n",
    "                           scalerParams=scalerParams,\n",
    "                           log_path=\"log_benchmark\",\n",
    "                           device=\"cuda:0\",\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=BENCHMARK_NAME,\n",
    "                           sim_config_path=SIM_CONFIG_PATH,\n",
    "                           sim_config_name=\"DEFAULT\",\n",
    "                           architecture_type=\"Classical\"                           \n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the augmented simulator using the benchmark datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim.train(benchmark.train_dataset, \n",
    "                save_path=None, \n",
    "                epochs=2, \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also save and load the model fitted parameters alongside its meta data using the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODELS = \"AirfRANSModel\"\n",
    "SAVE_PATH = TRAINED_MODELS+os.sep+ \"fully_connected\"\n",
    "torch_sim.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = TRAINED_MODELS +os.sep+ \"fully_connected\"\n",
    "torch_sim.restore(path=LOAD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the trained augmented simulator could be evaluated using the `evaluate_simulator` function of the `Benchmark` class. You can set on which dataset you want to evaluate your trained augmented simulator. The possibilites are `all`, `val`, `test`, `test_ood_topo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                  eval_batch_size=256000,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how your model performs directly by looking at the evaluation metrics resulted by from the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section-II (Train and Evaluate a new augmented simulator using LIPS platform) <a id='train_using_lips'></a>\n",
    "For intermediate level users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can implement an augmented simulator respecting the following template. Some of the functions are mandatory (`build_model`, `forward`, `process_dataset`, `post_process`) and others are optional (function to get metadata, save, load the model parameters).\n",
    "\n",
    "A best way to take advantage of all the offered functionalities by LIPS platform, is to keep the constructor `__init__` as it is presented and to customize the mandatory functions to construct your own architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Torch fully connected model\n",
    "\"\"\"\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Union\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from lips.dataset import DataSet\n",
    "from lips.dataset.scaler import Scaler\n",
    "from lips.logger import CustomLogger\n",
    "from lips.config import ConfigManager\n",
    "from lips.utils import NpEncoder\n",
    "\n",
    "class MyCustomFullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 sim_config_path: Union[pathlib.Path, str],\n",
    "                 bench_config_path: Union[str, pathlib.Path],\n",
    "                 sim_config_name: Union[str, None]=None,\n",
    "                 bench_config_name: Union[str, None]=None,\n",
    "                 name: Union[str, None]=None,\n",
    "                 scaler: Union[Scaler, None]=None,\n",
    "                 log_path: Union[None, pathlib.Path, str]=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if not os.path.exists(sim_config_path):\n",
    "            raise RuntimeError(\"Configuration path for the simulator not found!\")\n",
    "        if not str(sim_config_path).endswith(\".ini\"):\n",
    "            raise RuntimeError(\"The configuration file should have `.ini` extension!\")\n",
    "        sim_config_name = sim_config_name if sim_config_name is not None else \"DEFAULT\"\n",
    "        self.sim_config = ConfigManager(section_name=sim_config_name, path=sim_config_path)\n",
    "        self.bench_config = ConfigManager(section_name=bench_config_name, path=bench_config_path)\n",
    "        self.name = name if name is not None else self.sim_config.get_option(\"name\")\n",
    "        # scaler\n",
    "        self.scaler = scaler\n",
    "        # Logger\n",
    "        self.log_path = log_path\n",
    "        self.logger = CustomLogger(__class__.__name__, log_path).logger\n",
    "        # model parameters\n",
    "        self.params = self.sim_config.get_options_dict()\n",
    "        self.params.update(kwargs)\n",
    "\n",
    "        self.activation = {\n",
    "            \"relu\": F.relu,\n",
    "            \"sigmoid\": F.sigmoid,\n",
    "            \"tanh\": F.tanh\n",
    "        }\n",
    "\n",
    "        self.input_size = None if kwargs.get(\"input_size\") is None else kwargs[\"input_size\"]\n",
    "        self.output_size = None if kwargs.get(\"output_size\") is None else kwargs[\"output_size\"]\n",
    "\n",
    "        self.input_layer = None\n",
    "        self.input_dropout = None\n",
    "        self.fc_layers = None\n",
    "        self.dropout_layers = None\n",
    "        self.output_layer = None\n",
    "\n",
    "        #self.__build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build the model architecture\n",
    "        \"\"\"\n",
    "        linear_sizes = list(self.params[\"layers\"])\n",
    "\n",
    "        self.input_layer = nn.Linear(self.input_size, linear_sizes[0])\n",
    "        self.input_dropout = nn.Dropout(p=self.params[\"input_dropout\"])\n",
    "\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(in_f, out_f) \\\n",
    "            for in_f, out_f in zip(linear_sizes[:-1], linear_sizes[1:])])\n",
    "\n",
    "        self.dropout_layers = nn.ModuleList([nn.Dropout(p=self.params[\"dropout\"]) \\\n",
    "            for _ in range(len(self.fc_layers))])\n",
    "\n",
    "        self.output_layer = nn.Linear(linear_sizes[-1], self.output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \"\"\"\n",
    "        out = self.input_layer(data)\n",
    "        out = self.input_dropout(out)\n",
    "        for _, (fc_, dropout) in enumerate(zip(self.fc_layers, self.dropout_layers)):\n",
    "            out = fc_(out)\n",
    "            out = self.activation[self.params[\"activation\"]](out)\n",
    "            out = dropout(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    "    def process_dataset(self, dataset: DataSet, training: bool):\n",
    "        \"\"\"process the datasets for training and evaluation\n",
    "\n",
    "        This function transforms all the dataset into something that can be used by the neural network (for example)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : DataSet\n",
    "            A dataset that should be processed\n",
    "        training : bool, optional\n",
    "            indicate if we are in training phase or not, by default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataLoader\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        if training:\n",
    "            self._infer_size(dataset)\n",
    "            batch_size = self.params[\"train_batch_size\"]\n",
    "            extract_x, extract_y = dataset.extract_data()\n",
    "            if self.scaler is not None:\n",
    "                extract_x, extract_y = self.scaler.fit_transform(extract_x, extract_y)\n",
    "        else:\n",
    "            batch_size = self.params[\"eval_batch_size\"]\n",
    "            extract_x, extract_y = dataset.extract_data()\n",
    "            if self.scaler is not None:\n",
    "                extract_x, extract_y = self.scaler.transform(extract_x, extract_y)\n",
    "\n",
    "        torch_dataset = TensorDataset(torch.from_numpy(extract_x).float(), torch.from_numpy(extract_y).float())\n",
    "        data_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=self.params[\"shuffle\"])\n",
    "        return data_loader\n",
    "\n",
    "    def _post_process(self, data):\n",
    "        \"\"\"\n",
    "        This function is used to inverse the predictions of the model to their original state, before scaling\n",
    "        to be able to compare them with ground truth data\n",
    "        \"\"\"\n",
    "        if self.scaler is not None:\n",
    "            try:\n",
    "                processed = self.scaler.inverse_transform(data)\n",
    "            except TypeError:\n",
    "                processed = self.scaler.inverse_transform(data.cpu())\n",
    "        else:\n",
    "            processed = data\n",
    "        return processed\n",
    "\n",
    "    def _infer_size(self, dataset: DataSet):\n",
    "        \"\"\"Infer the size of the input and ouput variables\n",
    "        \"\"\"\n",
    "        *dim_inputs, self.output_size = dataset.get_sizes()\n",
    "        self.input_size = np.sum(dim_inputs)\n",
    "\n",
    "    def get_metadata(self):\n",
    "        res_json = {}\n",
    "        res_json[\"input_size\"] = self.input_size\n",
    "        res_json[\"output_size\"] = self.output_size\n",
    "        return res_json\n",
    "\n",
    "    def _save_metadata(self, path: str):\n",
    "        res_json = {}\n",
    "        res_json[\"input_size\"] = self.input_size\n",
    "        res_json[\"output_size\"] = self.output_size\n",
    "        with open((path / \"metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(obj=res_json, fp=f, indent=4, sort_keys=True, cls=NpEncoder)\n",
    "\n",
    "    def _load_metadata(self, path: str):\n",
    "        if not isinstance(path, pathlib.Path):\n",
    "            path = pathlib.Path(path)\n",
    "        with open((path / \"metadata.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            res_json = json.load(fp=f)\n",
    "        self.input_size = res_json[\"input_size\"]\n",
    "        self.output_size = res_json[\"output_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, the augmented simulator is implemented, you should also create a configuration which indicate all the hyper parameters required by this augmented simulator. An example of configuration file is shown in `configs/simulators/fully_connected.ini` and its content is shown below. \n",
    "\n",
    "The path and the section name of this configuration file should be given to your architecture as an argument (`sim_config_path`, `sim_config_name`) in order that it could be able to import all its required hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[DEFAULT]\n",
    "name = \"torch_fc\"\n",
    "layers = (300, 300, 300, 300)\n",
    "activation = \"relu\"\n",
    "layer = \"linear\"\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "metrics = (\"MAELoss\",)\n",
    "loss = {\"name\": \"MSELoss\",\n",
    "        \"params\": {\"size_average\": None,\n",
    "                   \"reduce\": None,\n",
    "                   \"reduction\": 'mean'}}\n",
    "device = \"cpu\"\n",
    "optimizer = {\"name\": \"adam\",\n",
    "             \"params\": {\"lr\": 3e-4}}\n",
    "train_batch_size = 128\n",
    "eval_batch_size = 128\n",
    "epochs = 10\n",
    "shuffle = False\n",
    "save_freq = False\n",
    "ckpt_freq = 50\n",
    "\n",
    "[CONFIG1]\n",
    "layers = (100, 100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the torch simulator which give as input your implemented augmented simulator (`MyCustomFullyConnected`) and offers a set of functionalities to train it and analyze its results. Optinally, you can also give a scaler (from the existing list of scalers or implement it yourself if you require a more advanced scaler), which is used by the `TorchSimulator` class to normalize your data before training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.torch_simulator import TorchSimulator\n",
    "from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative\n",
    "\n",
    "chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "\n",
    "torch_sim = TorchSimulator(name=\"torch_fc\",\n",
    "                           model=MyCustomFullyConnected,\n",
    "                           scaler=StandardScalerIterative,\n",
    "                           scalerParams=scalerParams,\n",
    "                           log_path=None,\n",
    "                           device=\"cpu\", # use \"cpu\" if you don't have a GPU available on your machine\n",
    "                           seed=42,\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=\"Benchmark1\",\n",
    "                           sim_config_path=SIM_CONFIG_PATH,\n",
    "                           sim_config_name=\"DEFAULT\", # use the default set of hyper parameters\n",
    "                           architecture_type=\"Classical\"\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim.train(benchmark.train_dataset, \n",
    "                save_path=None, \n",
    "                epochs=1, \n",
    "                train_batch_size=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                  eval_batch_size=256000,\n",
    "                                                  dataset=\"all\",\n",
    "                                                  shuffle=False,\n",
    "                                                  save_path=None,\n",
    "                                                  save_predictions=False\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section-III (Train an augmented simulator independently and evaluate it through LIPS) <a id='train_custom'></a>\n",
    "For advanced users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you require more functionalities that are not offered by LIPS platform (e.g., adding advanced regularizations into the training loop, or adding physics constraints in your model) you can implement your architecture independently from LIPS platform and use only the evaluation part of the framework to assess your model performance. \n",
    "\n",
    "In the following, we show a simple architecture with a training loop and how it can be evaluated by the LIPS platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 1: Implement your architecture based on Pytorch library in this Example\n",
    "\n",
    "**NB.** For Tensorflow users, there are also some examples provided in LIPS platform (see LIPS documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MyCustomFullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 name: str=\"MyCustomFC\",\n",
    "                 input_size: int=None,\n",
    "                 output_size: int=None,\n",
    "                 hidden_sizes: tuple=(100,100,),\n",
    "                 activation=F.relu\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        \n",
    "        self.activation = activation\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # model architecture\n",
    "        self.input_layer = nn.Linear(self.input_size, self.hidden_sizes[0])\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(in_f, out_f) \\\n",
    "                                        for in_f, out_f in zip(hidden_sizes[:-1], self.hidden_sizes[1:])])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], self.output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \"\"\"\n",
    "        out = self.input_layer(data)\n",
    "        for _, fc_ in enumerate(self.fc_layers):\n",
    "            out = fc_(out)\n",
    "            out = self.activation(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 2: Process the data to acquire the right Inputs and Outputs for your model alongside their dimensions\n",
    "This function uses a functionality offered by the Dataset class to extract the required inputs and outputs for the problem in hand, which facilitate the task. \n",
    "\n",
    "It also allows to create DataLoader from existing datasets.\n",
    "\n",
    "**NB.** However, the users could use their own extraction if they require to add further inputs (feature engineering or other operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, batch_size: int=128000, training: bool=False, shuffle: bool=False):\n",
    "    if training:\n",
    "        batch_size = batch_size\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "    else:\n",
    "        batch_size = batch_size\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "\n",
    "    torch_dataset = TensorDataset(torch.from_numpy(extract_x).float(), torch.from_numpy(extract_y).float())\n",
    "    data_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return data_loader\n",
    "\n",
    "def infer_input_output_size(dataset):\n",
    "    *dim_inputs, output_size = dataset.get_sizes()\n",
    "    input_size = np.sum(dim_inputs)\n",
    "    return input_size, output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 3: Implement your own Training, Validation and Prediction functions\n",
    "\n",
    "**train.** This function allows to train (adjust the parameters of) your defined model using the provided datasets.\n",
    "\n",
    "**validate.** This function allows to validate your model on a validation dataset. The validation step is not mendatory and is used only to trace the model behavior (overfitting or not). \n",
    "\n",
    "**predict.** This function allows to predict using the trained model. The `DataSet` class provides a function `reconstruct_output` which allows to reshape the predictions in the correct form which will be comparable with ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, val_loader=None, epochs=100, lr=3e-4, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # select your optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # select your loss function\n",
    "    loss_function = nn.MSELoss()\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        # set your model for training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        # iterate over the batches of data\n",
    "        pbar_batch=tqdm(train_loader)\n",
    "        for batch in pbar_batch:\n",
    "            data, target = batch\n",
    "            # transfer your data on proper device. The model and your data should be on the same device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # predict using your model on the current batch of data\n",
    "            prediction = model(data)\n",
    "            # compute the loss between prediction and real target\n",
    "            loss = loss_function(prediction, target)\n",
    "            # compute the gradient (backward pass of back propagation algorithm)\n",
    "            loss.backward()\n",
    "            # update the parameters of your model\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * len(data)\n",
    "        # the validation step is optional\n",
    "        if val_loader is not None:\n",
    "            val_loss = validate(model, val_loader, device)\n",
    "            val_losses.append(val_loss)\n",
    "        mean_loss = total_loss / len(train_loader.dataset)\n",
    "        print(f\"Train Epoch: {epoch}   Avg_Loss: {mean_loss:.5f}\")\n",
    "        train_losses.append(mean_loss)\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    # set the model for evaluation (no update of the parameters)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    loss_function = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        pbar_batch=tqdm(val_loader)\n",
    "        for batch in val_loader:\n",
    "            data, target = batch\n",
    "            data.to(device)\n",
    "            target.to(device)\n",
    "            prediction = model(data)\n",
    "            loss = loss_function(prediction, target)\n",
    "            total_loss += loss.item()*len(data)\n",
    "        mean_loss = total_loss / len(val_loader.dataset)\n",
    "        print(f\"Eval:   Avg_Loss: {mean_loss:.5f}\")\n",
    "    return mean_loss\n",
    "\n",
    "def predict(model, dataset, device):\n",
    "    # set the model for the evaluation\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    observations = []\n",
    "    test_loader = process_dataset(dataset, training=False, shuffle=False)\n",
    "    # we dont require the computation of the gradient\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            data, target = batch\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            prediction = model(data)\n",
    "            \n",
    "            if device == torch.device(\"cpu\"):\n",
    "                predictions.append(prediction.numpy())\n",
    "                observations.append(target.numpy())\n",
    "            else:\n",
    "                predictions.append(prediction.cpu().data.numpy())\n",
    "                observations.append(target.cpu().data.numpy())\n",
    "    # reconstruct the prediction in the proper required shape of target variables\n",
    "    predictions = np.concatenate(predictions)\n",
    "    predictions = dataset.reconstruct_output(predictions)\n",
    "    # Do the same for the real observations\n",
    "    observations = np.concatenate(observations)\n",
    "    observations = dataset.reconstruct_output(observations)\n",
    "\n",
    "    return predictions, observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = process_dataset(benchmark.train_dataset, training=True)\n",
    "input_size, output_size = infer_input_output_size(benchmark.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "MyCustomFullyConnected(\n",
      "  (input_layer): Linear(in_features=7, out_features=50, bias=True)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=50, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=50, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MyCustomFullyConnected(input_size=input_size,\n",
    "                               output_size=output_size,\n",
    "                               hidden_sizes=(50,100,50),\n",
    "                               activation=F.relu\n",
    "                               )\n",
    "model.to(device)\n",
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [02:18<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [02:18<00:00, 138.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0   Avg_Loss: 1508993.76032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, _ = train(model, train_loader, epochs=1, device=device, lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction on `test_dataset`\n",
    "This dataset has the same distribution as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x-velocity': array([18.5462  , 18.546204, 18.50614 , ..., 36.569386, 36.566185,\n",
       "        36.562996], dtype=float32),\n",
       " 'y-velocity': array([0.64630246, 0.6463029 , 0.64793926, ..., 1.4456995 , 1.445418  ,\n",
       "        1.445134  ], dtype=float32),\n",
       " 'pressure': array([-13.368277 , -13.3682785, -13.339288 , ..., -26.060314 ,\n",
       "        -26.058012 , -26.055717 ], dtype=float32),\n",
       " 'turbulent_viscosity': array([-0.07912619, -0.07912672, -0.07213913, ..., -0.03456163,\n",
       "        -0.0349595 , -0.03535855], dtype=float32)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35849332,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"x-velocity\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35849332,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[\"x-velocity\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 35849332 but corresponding boolean dimension is 18515415",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Desktop\\EPFL\\ML4Science\\ml4physim_startingkit\\4_How_to_contribute.ipynb Cell 60\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m evaluator \u001b[39m=\u001b[39m AirfRANSEvaluation(config_path \u001b[39m=\u001b[39m BENCH_CONFIG_PATH,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                scenario \u001b[39m=\u001b[39m BENCHMARK_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                data_path \u001b[39m=\u001b[39m DIRECTORY_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                log_path \u001b[39m=\u001b[39m LOG_PATH)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m observation_metadata \u001b[39m=\u001b[39m benchmark\u001b[39m.\u001b[39mtrain_dataset\u001b[39m.\u001b[39mextra_data\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m metrics \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39;49mevaluate(observations\u001b[39m=\u001b[39;49mobservations,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                              predictions\u001b[39m=\u001b[39;49mpredictions,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                              observation_metadata\u001b[39m=\u001b[39;49mobservation_metadata)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ML4Science/ml4physim_startingkit/4_How_to_contribute.ipynb#Y110sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(metrics)\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\evaluation\\airfrans_evaluation.py:82\u001b[0m, in \u001b[0;36mAirfRANSEvaluation.evaluate\u001b[1;34m(self, observations, predictions, observation_metadata, save_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_metadata \u001b[39m=\u001b[39m observation_metadata\n\u001b[0;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dict\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_evaluation(cat)\n\u001b[0;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\evaluation\\airfrans_evaluation.py:100\u001b[0m, in \u001b[0;36mAirfRANSEvaluation._dispatch_evaluation\u001b[1;34m(self, category)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m category \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMACHINE_LEARNING:\n\u001b[0;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dict[category]:\n\u001b[1;32m--> 100\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_ml()\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m category \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPHYSICS_COMPLIANCES:\n\u001b[0;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dict[category]:\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ml4science\\lib\\site-packages\\lips\\evaluation\\airfrans_evaluation.py:134\u001b[0m, in \u001b[0;36mAirfRANSEvaluation.evaluate_ml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m pred_pressure \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions[\u001b[39m\"\u001b[39m\u001b[39mpressure\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    133\u001b[0m surface_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_metadata[\u001b[39m\"\u001b[39m\u001b[39msurface\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 134\u001b[0m tmp_surface \u001b[39m=\u001b[39m metric_fun(true_pressure[surface_data\u001b[39m.\u001b[39;49mastype(\u001b[39mbool\u001b[39;49m)], pred_pressure[surface_data\u001b[39m.\u001b[39mastype(\u001b[39mbool\u001b[39m)])\n\u001b[0;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMACHINE_LEARNING][metric_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_surfacic\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mpressure\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(tmp)}\n\u001b[0;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m surfacic for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, metric_name, \u001b[39m\"\u001b[39m\u001b[39mpressure\u001b[39m\u001b[39m\"\u001b[39m, tmp_surface)\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 35849332 but corresponding boolean dimension is 18515415"
     ]
    }
   ],
   "source": [
    "from lips.evaluation.airfrans_evaluation import AirfRANSEvaluation\n",
    "\n",
    "evaluator = AirfRANSEvaluation(config_path = BENCH_CONFIG_PATH,\n",
    "                               scenario = BENCHMARK_NAME,\n",
    "                               data_path = DIRECTORY_NAME,\n",
    "                               log_path = LOG_PATH)\n",
    "\n",
    "observation_metadata = benchmark.train_dataset.extra_data\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on `test_ood_dataset`\n",
    "This dataset has a different distribution in comparison to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, observations = predict(model, benchmark._test_ood_dataset, device=device)\n",
    "evaluator = AirfRANSEvaluation(config_path = BENCH_CONFIG_PATH,\n",
    "                               scenario = BENCHMARK_NAME,\n",
    "                               data_path = DIRECTORY_NAME,\n",
    "                               log_path = LOG_PATH)\n",
    "\n",
    "metrics = evaluator.evaluate(observations=observations,\n",
    "                             predictions=predictions,\n",
    "                             observation_metadata=observation_metadata)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
